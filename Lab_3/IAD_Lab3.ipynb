{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b52bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Практична робота 3 Винник Михайло ФБ-52мп"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d8ea37",
   "metadata": {},
   "source": [
    "## Завдання 1: Повнозв'язані нейронні мережі (FNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647bde64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Встановлюю фіксований seed для відтворюваності результатів\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b2903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дані успішно завантажено!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('earthquake_data_tsunami.csv')\n",
    "    print(\"Дані успішно завантажено!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Помилка: Файл 'earthquake_data_tsunami.csv' не знайдено.\")\n",
    "\n",
    "# Підготовка даних\n",
    "df = df.fillna(0) # Заповнення пропусків\n",
    "X = df.drop(columns=['tsunami'])\n",
    "y = df['tsunami']\n",
    "\n",
    "# Розбиття на тренувальну та тестову вибірки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Масштабування\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ab48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Початок навчання...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\misha\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6320 - loss: 0.6530 - val_accuracy: 0.7840 - val_loss: 0.5590\n",
      "Epoch 2/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.4904 - val_accuracy: 0.8160 - val_loss: 0.4480\n",
      "Epoch 3/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8160 - loss: 0.4144 - val_accuracy: 0.8320 - val_loss: 0.4095\n",
      "Epoch 4/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8360 - loss: 0.3795 - val_accuracy: 0.8320 - val_loss: 0.3934\n",
      "Epoch 5/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8320 - loss: 0.3685 - val_accuracy: 0.8240 - val_loss: 0.3864\n",
      "Epoch 6/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8440 - loss: 0.3538 - val_accuracy: 0.8320 - val_loss: 0.3774\n",
      "Epoch 7/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8360 - loss: 0.3321 - val_accuracy: 0.8400 - val_loss: 0.3697\n",
      "Epoch 8/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8500 - loss: 0.3233 - val_accuracy: 0.8320 - val_loss: 0.3648\n",
      "Epoch 9/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8520 - loss: 0.3335 - val_accuracy: 0.8320 - val_loss: 0.3629\n",
      "Epoch 10/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8460 - loss: 0.3193 - val_accuracy: 0.8320 - val_loss: 0.3580\n",
      "Epoch 11/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8640 - loss: 0.2984 - val_accuracy: 0.8320 - val_loss: 0.3574\n",
      "Epoch 12/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 0.3138 - val_accuracy: 0.8320 - val_loss: 0.3555\n",
      "Epoch 13/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8660 - loss: 0.2787 - val_accuracy: 0.8320 - val_loss: 0.3546\n",
      "Epoch 14/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8640 - loss: 0.2825 - val_accuracy: 0.8240 - val_loss: 0.3560\n",
      "Epoch 15/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 0.2984 - val_accuracy: 0.8160 - val_loss: 0.3520\n",
      "Epoch 16/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.2917 - val_accuracy: 0.8160 - val_loss: 0.3455\n",
      "Epoch 17/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8720 - loss: 0.2789 - val_accuracy: 0.8080 - val_loss: 0.3494\n",
      "Epoch 18/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8760 - loss: 0.2764 - val_accuracy: 0.8160 - val_loss: 0.3490\n",
      "Epoch 19/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8860 - loss: 0.2746 - val_accuracy: 0.8320 - val_loss: 0.3512\n",
      "Epoch 20/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8840 - loss: 0.2663 - val_accuracy: 0.8320 - val_loss: 0.3481\n",
      "Epoch 21/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8780 - loss: 0.2769 - val_accuracy: 0.8320 - val_loss: 0.3451\n",
      "Epoch 22/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8840 - loss: 0.2597 - val_accuracy: 0.8320 - val_loss: 0.3456\n",
      "Epoch 23/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8860 - loss: 0.2525 - val_accuracy: 0.8400 - val_loss: 0.3515\n",
      "Epoch 24/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8920 - loss: 0.2432 - val_accuracy: 0.8400 - val_loss: 0.3477\n",
      "Epoch 25/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8820 - loss: 0.2538 - val_accuracy: 0.8400 - val_loss: 0.3461\n",
      "Epoch 26/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8740 - loss: 0.2555 - val_accuracy: 0.8400 - val_loss: 0.3478\n",
      "Epoch 27/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8880 - loss: 0.2589 - val_accuracy: 0.8320 - val_loss: 0.3396\n",
      "Epoch 28/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8920 - loss: 0.2504 - val_accuracy: 0.8320 - val_loss: 0.3377\n",
      "Epoch 29/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8960 - loss: 0.2386 - val_accuracy: 0.8320 - val_loss: 0.3440\n",
      "Epoch 30/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 0.2329 - val_accuracy: 0.8400 - val_loss: 0.3444\n"
     ]
    }
   ],
   "source": [
    "# Архітектура моделі\n",
    "model_fnn = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dropout(0.3),  # Запобігає перенавчанню\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid') # sigmoid для бінарної класифікації (0 або 1)\n",
    "])\n",
    "\n",
    "model_fnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Навчання\n",
    "print(\"Початок навчання...\")\n",
    "history_fnn = model_fnn.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=30, \n",
    "    batch_size=16, \n",
    "    validation_split=0.2, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33759c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "Точність нейромережі: 0.8471\n",
      "\n",
      "Звіт класифікації:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87        91\n",
      "           1       0.80      0.85      0.82        66\n",
      "\n",
      "    accuracy                           0.85       157\n",
      "   macro avg       0.84      0.85      0.84       157\n",
      "weighted avg       0.85      0.85      0.85       157\n",
      "\n",
      "Точність Random Forest (для порівняння): 0.9299\n"
     ]
    }
   ],
   "source": [
    "# Оцінка на тестових даних\n",
    "loss, acc = model_fnn.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "y_pred = (model_fnn.predict(X_test_scaled) > 0.5).astype(int)\n",
    "\n",
    "print(f\"\\nТочність нейромережі: {acc:.4f}\")\n",
    "print(\"\\nЗвіт класифікації:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Порівняння з Random Forest (як у лабі 1)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "print(f\"Точність Random Forest (для порівняння): {rf.score(X_test_scaled, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf23d62",
   "metadata": {},
   "source": [
    "## Завдання 2: Згорткові нейронні мережі (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e34eddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = 'intel_images/seg_train' \n",
    "test_dir = 'intel_images/seg_test'\n",
    "\n",
    "img_size = (150, 150)\n",
    "batch_size = 32\n",
    "\n",
    "# Генератори з аугментацією (для кращого навчання)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "try:\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "except:\n",
    "    print(\"Не знайдено зображень. Перевірте шлях до папки!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15adf8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\misha\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 259ms/step - accuracy: 0.5980 - loss: 1.0536 - val_accuracy: 0.7293 - val_loss: 0.7323\n",
      "Epoch 2/5\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 253ms/step - accuracy: 0.7577 - loss: 0.6570 - val_accuracy: 0.8007 - val_loss: 0.5667\n",
      "Epoch 3/5\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 245ms/step - accuracy: 0.8047 - loss: 0.5350 - val_accuracy: 0.7967 - val_loss: 0.5717\n",
      "Epoch 4/5\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 246ms/step - accuracy: 0.8347 - loss: 0.4521 - val_accuracy: 0.8403 - val_loss: 0.4701\n",
      "Epoch 5/5\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 254ms/step - accuracy: 0.8658 - loss: 0.3742 - val_accuracy: 0.8437 - val_loss: 0.4526\n"
     ]
    }
   ],
   "source": [
    "num_classes = train_generator.num_classes\n",
    "\n",
    "model_cnn = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# навчання (зменшив кількість епох для швидкості, можна поставити більше)\n",
    "history_cnn = model_cnn.fit(train_generator, epochs=5, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3377bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Навчання Transfer Learning моделі...\n",
      "Epoch 1/5\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 994ms/step - accuracy: 0.7991 - loss: 0.5486 - val_accuracy: 0.8510 - val_loss: 0.3748\n",
      "Epoch 2/5\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 967ms/step - accuracy: 0.8459 - loss: 0.4140 - val_accuracy: 0.8683 - val_loss: 0.3521\n",
      "Epoch 3/5\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 955ms/step - accuracy: 0.8648 - loss: 0.3675 - val_accuracy: 0.8763 - val_loss: 0.3282\n",
      "Epoch 4/5\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 954ms/step - accuracy: 0.8696 - loss: 0.3513 - val_accuracy: 0.8817 - val_loss: 0.3230\n",
      "Epoch 5/5\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 956ms/step - accuracy: 0.8746 - loss: 0.3367 - val_accuracy: 0.8800 - val_loss: 0.3284\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Завантажуємо VGG16 без верхніх шарів\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "base_model.trainable = False # заморожуємо ваги\n",
    "\n",
    "# додаю свої шари\n",
    "model_tl = keras.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_tl.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Навчання Transfer Learning моделі...\")\n",
    "history_tl = model_tl.fit(train_generator, epochs=5, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3327dddf",
   "metadata": {},
   "source": [
    "## Завдання 3: Класифікація тексту (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f594f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Завантаження даних...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10000  # Кількість слів\n",
    "maxlen = 200          # Довжина відгуку\n",
    "\n",
    "print('Завантаження даних...')\n",
    "(input_train, y_train_nlp), (input_test, y_test_nlp) = imdb.load_data(num_words=max_features) # датасет IMDB Movie Reviews\n",
    "\n",
    "# вирівнювання довжини\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691a9c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Навчання LSTM...\n",
      "Epoch 1/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.6406 - loss: 0.6186 - val_accuracy: 0.7680 - val_loss: 0.5024\n",
      "Epoch 2/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 81ms/step - accuracy: 0.8231 - loss: 0.4049 - val_accuracy: 0.8592 - val_loss: 0.3407\n",
      "Epoch 3/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 99ms/step - accuracy: 0.8665 - loss: 0.3260 - val_accuracy: 0.7834 - val_loss: 0.4693\n",
      "Epoch 4/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.8777 - loss: 0.3020 - val_accuracy: 0.8406 - val_loss: 0.3661\n",
      "Epoch 5/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 81ms/step - accuracy: 0.8949 - loss: 0.2670 - val_accuracy: 0.8624 - val_loss: 0.3400\n"
     ]
    }
   ],
   "source": [
    "model_lstm = keras.Sequential([\n",
    "    layers.Embedding(max_features, 32),\n",
    "    layers.LSTM(32),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_lstm.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Навчання LSTM...\")\n",
    "history_lstm = model_lstm.fit(input_train, y_train_nlp, epochs=5, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b769b50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Завантаження GloVe вектори...\n",
      "Знайдено 400000 векторів слів.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Конвертовано слів: 9793, Не знайдено в GloVe: 203\n",
      "Початок навчання моделі з GloVe...\n",
      "Epoch 1/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - accuracy: 0.6479 - loss: 0.6246 - val_accuracy: 0.7250 - val_loss: 0.5522\n",
      "Epoch 2/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.7344 - loss: 0.5389 - val_accuracy: 0.7502 - val_loss: 0.5152\n",
      "Epoch 3/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 83ms/step - accuracy: 0.7710 - loss: 0.4849 - val_accuracy: 0.7526 - val_loss: 0.5087\n",
      "Epoch 4/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.7944 - loss: 0.4417 - val_accuracy: 0.7958 - val_loss: 0.4465\n",
      "Epoch 5/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.8106 - loss: 0.4147 - val_accuracy: 0.8202 - val_loss: 0.4093\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras import layers, models\n",
    "glove_dir = 'glove.6B.100d.txt'\n",
    "embedding_dim = 100\n",
    "max_features = 10000\n",
    "\n",
    "# завантажую словник GloVe\n",
    "embeddings_index = {}\n",
    "if os.path.exists(glove_dir):\n",
    "    print(\"Завантаження GloVe вектори...\")\n",
    "    with open(glove_dir, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print(f\"Знайдено {len(embeddings_index)} векторів слів.\")\n",
    "\n",
    "    # створюю матрицю з правильним зсувом індексів\n",
    "    word_index = imdb.get_word_index()\n",
    "    embedding_matrix = np.zeros((max_features, embedding_dim))\n",
    "    \n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        # Враховуємо зсув +3, який робить imdb.load_data()\n",
    "        idx = i + 3 #Keras використовує індекси: 0 (padding), 1 (start), 2 (OOV). Тому реальні слова починаються з індексу 3.\n",
    "        if idx < max_features:\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[idx] = embedding_vector\n",
    "                hits += 1\n",
    "            else:\n",
    "                misses += 1\n",
    "    \n",
    "    print(f\"Конвертовано слів: {hits}, Не знайдено в GloVe: {misses}\")\n",
    "\n",
    "    # Модель\n",
    "    model_glove = models.Sequential([\n",
    "        layers.Embedding(max_features, \n",
    "                         embedding_dim, \n",
    "                         embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                         trainable=False), # False = не змінювати ваги GloVe\n",
    "        layers.LSTM(32),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model_glove.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(\"Початок навчання моделі з GloVe...\")\n",
    "    history_glove = model_glove.fit(input_train, y_train_nlp, epochs=5, batch_size=128, validation_split=0.2)\n",
    "\n",
    "else:\n",
    "    print(f\"УВАГА: Файл '{glove_dir}' не знайдено! Скачайте його з Kaggle.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
